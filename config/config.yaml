preprocess:
  data_dir: /data/corpus/open_subtitles # Corpus directory
  save_dir: data                        # Directory for saving generated data
  size: 10000                           # Size of the vocabulary
  max_len: 15                           # Max length of the inputs and outputs(0 for disabling max_len)
  normalize: True                       # Normalize the strings
model:
  n_layers: 2                           # number of encoder layers
  bidir: True                           # bidirectional rnn encoder
  attention: dot                        # attention mechanism(dot / general / concat)
solver:
  teacher_forcing_ratio: 1.0
  train_set: []
  batch_size: 64
  total_step: 50000
  valid_set: []
  valid_step: 1000
  log_step: 100
  test_set: []
  save_dir: save
  log_dir: log
